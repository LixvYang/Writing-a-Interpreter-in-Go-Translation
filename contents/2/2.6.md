# 2.6解析表达式
个人看法，我认为解析表达式是我写解析器最有意思的部分。作为我们仅仅看到的，解析语句是相当直观。我们通过“左到右”tokens，期望或拒绝下一个token，如果一切合适我们将返回一个AST节点。

解析表达式，在另一方面，包含了更多挑战。运算符优先级可能是第一个想到的，最好用一个例子来说明。让我们说我们要解析以下算数表达式：
```go
5 * 5 + 10
```
我们在这里想要一个表达式像这样的AST:
```go
((5 * 5) + 10)
```
也就是说，5 * 5在AST里需要变得更深并且在添加之前进行评估。为了生产一个看起来像这样的AST，解析器已经知道操作运算符*比+更高有优先级。这是对操作运算符最常见的例子了，但是也有许多种同样重要的实例。考虑一下这个表达式：
```go
5 * (5 + 10)
```
这里的括号将5和10组合在一起，并给它们一个“优先级”,现在必须在乘法之前评估加法。那是因为括号具有比*更高的优先级。我们很快就会看到，还有一些案例优先级起着至关重要的作用。

另一个大的挑战是在表达式里有相同种类的tokens能发生在许多位置。和这个相反，let token仅仅只能发生在let语句的开头，这使得很容易确定语句的其余部分应该是什么。现在看这个表达式：
```go
-5 - 10
```
这里的-操作符发生在表达式的开头，作为一个前缀操作符，并且然后作为中间的中缀运算符。此处出现了相同挑战的变体：
```go
5 * (add(2,3) + 10)
```
即使你可能不认识括弧作为运算符，它们给我们带来了和以前例子里相同的问题。本例中的一组外括号比表示分组表达式。内部对表示“调用表达式”。token位置的有效性现在取决于上下文、前后的token以及它们的优先级。

## Monkey种的表达式
在 Monkey 编程语言中，除了let和return语句之外，所有的东西都是一个表达式。 这些表达方式多种多样。

Monkey设计前缀运算符的表达式：
```go
-5
!true
!false
```
并且当然它还有中缀运算符(或中间运算符)
```go
5 + 5
5 - 5
5 / 5
5 * 5
```
除了这些基本的算术运算符外，还有下面的比较运算符:
```go
foo == bar
foo != bar
foo < bar
foo > bar
```
并且当然，作为我们之前看到的，我们能使用括号给表达式分组并影响评估顺序：
```go
5 * (5 + 5)
((5 + 5) * 5) * 5
```
然后是调用表达式：
```go
add(2, 3)
add(add(2, 3), add(5, 10))
max(5, add(5, (5 * 5)))
```
也有标识符表达式:
```go
foo * bar / foobar
add(foo, bar)
```
在Monkey中的函数是第一类公民，使得，函数字面量也是表达式。我们能使用let语句去绑定给函数一个名字。函数字面量仅仅只是语句中的表达式：
```
let add = fn(x, y) { return x + y };
```
并且在这里我们使用一个函数字面量代替标识符:
```
fn(x, y) { return x + y }(5, 5)
(fn(x) { return x }(5) + 10 ) * 10
```
与许多广泛使用的编程语言相比，我们在Monkey中也有“if 表达式”：
```
let result = if (10 > 5) { true } else { false };
result // => true
```
看着所有这些不同形式的表达式，很明显我们需要一种非常好的方法来正确解析它们，并以可理解和可扩展的方式进行解析。我们根据当前token做什么的就方法不会让我们走得很远-至少不是不想撤掉我们的头发。这就是Vaughan Partt的用武之地。

## 自顶而下的运算符优先级（或：Pratt Parsing）
在他的论文上“自顶而下的运算符优先级”Vaughan Pratt提出一种解析表达式，用他的话说：
> […] is very simple to understand, trivial to implement, easy to use, extremely efficient in practice if not in theory, yet flexible enough to meet most reasonable syntactic needs of users […]

> […] 非常容易理解，易于实现，易于使用，效率极高,在实践中，如果不是理论上，但足够灵活以满足用户最合理的语法需求 […]

论文发表于1973年，但是在此后的许多年里，Partt提出的想法没有大量的追随者。直到最近几年，其他程序员才重新发现了Partt的论文，写了他并使Partt的解析方法越来越受欢迎。Douglas Crockford 的（“JavaScript: The Good Parts”成名）文章称为([自定而下运算符优先级](http://crockford.com/javascript/)，展示了如何将 Pratt 的想法转化为 JavaScript（Crockford 在构建 JSLint 时所做的）。 然后是优秀的“游戏编程模式”一书的作者 Bob Nystrom [强烈推荐的文章](http://journal.stuffwithstuff.com/2011/03/19/pratt-parsers-expression-parsing-made-easy/)，它通过提供简洁的 Java 示例代码使 Pratt 的方法非常易于理解和遵循。

三者描述的解析方式称为自顶而下运算符优先级解析或Partt解析是作为基于上下无关文法和Backus-Naur-Form的解析器的替代方案而发明的。

这也是主要区别：而不是关联解析函数(想想我们的parseLetStatement方法)与语法规则(在BNF或EBNF中定义)，Pratt将这些函数(他称之为“语义代码”)与单个token类型相关联。这个想法的一个关键部分是每个token类型可以有两个与之关联的解析函数，这取决于token的位置 - 中缀或前缀。

我猜这还是没有什么意义。我们从来没有看到如何联系解析函数和语法规则，所以使用token 类型的想法而不是这些规则的想法并没有注册为任何真正新颖或具有启发性的东西。老实说：在编写本书时，我正面临着先有鸡还是先有蛋的问题。用抽象术语解释这个算法会更好吗？然后显示实现，可能会导致您在页面之间跳来跳去，或者显示带有以下解释的实现，导致您可能跳过实现而没有从解释中得到更多？

答案是，我决定，拒绝这两种想法。我们将要代替的是开始实现我们解析器的表达式解析部分。那我们就来仔细看看在它和它之间的算法。之后我们将扩展并完成它，以便它能够解析所有Monkey中可能的表达式。

在我们开始编写任何代码之前，让我们县弄懂技术。

## 技术
一个前缀运算符是一个在操作数前面的运算符。例如：
```go
--5
```
这里的运算符是--(递减)，操作符是整数文字5，运算符是前缀位置。

一个后缀运算符是一个在操作数后方的运算符。例如:
```go
foobar++
```
这里的运算符是++(递增)，操作数是标识符foobar和在后方位置的运算符。我们将绑定的Monkey解释器将不会有后缀运算符。不是因为技术限制，而是纯粹为了限制本书的范围。

现在，中缀运算符在两个整数5和8中间的位置。中缀运算符出现在二分表达式中-运算符有两个操作数。

我们已经偶然发现并且稍后会再次找到的另一个术语是运算符优先级。 替代术语是操作顺序，它应该更清楚地说明运算符优先级描述的是什么：不同的运算符具有哪些优先级。 规范的例子是这个，我们之前看到过：
```go
5 + 5 * 10
```
表达式的记过是55而不是100.并且因为*运算符有一个更高的优先级，一个“高排位”。它比起+运算符更重要。它得到评估在其他运算符之前。我有事认为运算符优先级作为“运算符粘性”，运算符旁边的操作数“坚持”了多少。

这里有许多基本术语：前缀，后缀，中缀运算符和优先级。但更重要的是我们稍后会记住这些简单的定义，我们将在其他地方使用这些术语。但是现在，让我们打字并写代码！

## 准备AST
我们需要为表达式解析做的第一件事是准备我们的 AST。 正如我们之前看到的，Monkey 中的程序是一系列语句。 有些是 let 语句，有些是 return 语句。 我们需要在 AST 中添加第三种类型的语句：表达式语句。

这可能听起来很困惑，在我告诉你let和return语句是Monkey中仅有的语句后。但是一个表达式语句不是真正的特殊语句;它是仅由一个表达式组成的语句。这只是一个包装。我们需要它，因为它是在Monkey中编写以下代码是完全合法的：
```
let x = 5;
x + 10;
```
第一行是let语句，第二行是一个表达式语句。其他语言没有这些表达式语句，但大多数脚本语言由。这使得仅由一行表达式的组成称为可能。所以让我们添加这个节点类型给我们的AST：
```go
// ast/ast.go

type ExpressionStatement struct {
    Token token.Token // the first token of the expression
    Expression Expression
}

func (es *ExpressionStatement) statementNode() {}
func (es *ExpressionStatement) TokenLiteral() string { return es.Token.Literal }
```
ast.ExpressStatement类型由两个字段：每个节点都有的Token字段，和其中包含表达式的Expression字段。ast.ExpressionStatement实现了ast.Statement接口，这意味着我们可以将它添加到ast.Program的Statements切片中。这就是我们添加ast.ExpressionStatement的全部原因。

随着ast.ExpressionStatement的定义我们可以继续解析器的工作。但相反，让我们通过向AST节点添加String()方法，让我们的生活变得更轻松。这将使我们打印用于调试的AST节点并将它们与其他AST节点进行比较。这将在测试中非常方便！

我们将使String()方法成为ast.Node接口的一部分：
```go
// ast/ast.go

type Node interface {
    TokenLiteral() string
    String()       string
}

```
现在在我们ast包中的每个节点类型都已经实现了方法。随着这个改变，我们的代码将无法编译，因为编译器抱怨我们的AST节点不完全实现新的节点接口。让我们从 *ast.Program 开始，先添加它的 String() 方法：
```go
// ast/ast.go

import (
// [...]
    "bytes"
)
func (p *Program) String() string {
    var out bytes.Buffer
    for _, s := range p.Statements {
        out.WriteString(s.String())
    }
        return out.String()
    }
```
这个方法没有做太多。它仅仅创建一个缓冲区并且写下每个String方法给他的每个语句的值。并且然后它返回缓冲区作为一个字符。. 、它将大部分工作委托给 *ast.Program 的声明。

“真正的工作”发生在我们三种语句类型 ast.LetStatement、ast.ReturnStatement 和 ast.ExpressionStatement 的 String() 方法中。
```go
// ast/ast.go
func (ls *LetStatement) String() string {
    var out bytes.Buffer

    out.WriteString(ls.TokenLiteral() + " ")
    out.WriteString(ls.Name.String())
    out.WriteString(" = ")

    if ls.Value != nil {
        out.WriteString(ls.Value.String())
    }

    out.WriteString(";")
    return out.String()
}

func (rs *ReturnStatement) String() string {
    var out bytes.Buffer

    out.WriteString(rs.TokenLiteral() + " ")
    
    if rs.ReturnValue != nil {
    out.WriteString(rs.ReturnValue.String())
    }

    out.WriteString(";")

    return out.String()
}

func (es *ExpressionStatement) String() string {
    if es.Expression != nil {
        return es.Expression.String()
    }
    return ""
}
```
稍后，当我们可以完全构建表达式时，将取消 nil 检查。现在我们只需要向 ast.Identifier 添加最后一个 String() 方法：
```go
// ast/ast_test.go
package ast

import (
    "monkey/token"
    "testing"
)
func TestString(t *testing.T) {
	program := &Program{
		Statements: []Statement{
			&LetStatement{
				Token: token.Token{Type: token.LET, Literal: "let"},
				Name: &Identifier{
					Token: token.Token{Type: token.IDENT, Literal: "myVar"},
					Value: "myVar",
				},
				Value: &Identifier{
					Token: token.Token{Type: token.IDENT, Literal: "anotherVar"},
					Value: "anotherVar",
				},
			},
		},
	}

	if program.String() != "let myVar = anotherVar;" {
		t.Errorf("program.String() wrong. got=%q", program.String())
	}
}
```
在这个测试中我们手动构建了AST。在为解析器编写测试时，我们不会对解析器产生的AST进行断言。处于演示目的，这个测试向我们展示了如何为我们的解析器添加另一个易于阅读的测试层。这在解析表达式时会特别方便。所以好消息是：准备工作已经完成！是时候编写一个Pratt解析器了。

## 实现Pratt解析器
一个Pratt解析器主要想法是联系解析函数(Prate称之为“语义代码)
与token类型的关联。每当遇到此标记类型时，都会调用解析函数来解析当前适当的表达式并返回表示它的AST节点。每种token类型最多可以有两个与之关联的解析函数，具体取决于token是在前缀还是中缀位置中找到。

我们要做的第一件事是建立联系。我们定义两种类型的函数一个前缀解析函数和一个中缀解析函数。
```go
// parser/parser.go

type (
    prefixParseFn func() ast.Expression
    infixParseFn func(ast.Expression) ast.Expression
)
```
这两种函数类型都返回一个ast.Expression，因为这就是我们要解析的内容。但是仅仅中缀函数有一个参数：另一个ast.Expression。这个参数是被解析的中缀运算符的“左侧”。前缀运算符没有左边，前定义。我知道这还没有什么意义，但请耐心等待，即将看到它是如何运行的。所以现在，仅仅记住当我们遇到关联的token时会调用prefixParseFns输入前缀位置，当我们在中缀位置遇到token类型时调用 infixParseFn 。

为了我们的解析器去得到正确的prefixParseFn 或 infixParseFn对于正确的token类型，我们为Parser结构添加两个maps。
```go
// parser/parser.go

type Parser struct {
    l *lexer.Lexer
    errors []string
    curToken token.Token
    peekToken token.Token

    prefixParseFns map[token.TokenType]prefixParseFn
    infixParseFns map[token.TokenType]infixParseFn
}
```
随着maps存在，我们就能检查是否合适的map(中缀或前缀)有一个和curToken.Type联系的解析函数。

我们还为 Parser 提供了两个辅助方法，用于向这些maps添加条目：
```go
// parser/parser.go

func (p *Parser) registerPrefix(tokenType token.TokenType, fn prefixParseFn) {
    p.prefixParseFns[tokenType] = fn
}
func (p *Parser) registerInfix(tokenType token.TokenType, fn infixParseFn) {
    p.infixParseFns[tokenType] = fn
}
```
现在我们准备得到算法的核心。
## 身份识别
我们将可能开始最简单的表达式在Monkey语言中：标识符。使用在表达式语句中的标识符看起来像这样：
```
foobar;
```
当然，foobar是可变的并且标识符也是其他表达式的内容，所以仅仅在表达式语句：
```
add(foobar,barfoo);
foobar + barfoo;
if (foobar) {
    //[...]
}
```
在这里我们有标识符作为函数调用的参数，作为中缀表达式中的操作数和作为独立表达式作为条件的一部分。它们可以在所有这些上下文中使用，因为标识符像表达式，就像1 + 2一样。就像其他表达式标识符一样产生一个值：它们评估为它们所绑定的值。

我们将开始一个测试：
```go
// parser/parser_test.go

func TestIdentifierExpression(t *testing.T) {
	input := "foobar;"

	l := lexer.New(input)
	p := New(l)
	program := p.ParseProgram()
	checkParserErrors(t, p)

	if len(program.Statements) != 1 {
		t.Fatalf("program has not enough statements. got=%d",
			len(program.Statements))
	}
	stmt, ok := program.Statements[0].(*ast.ExpressionStatement)
	if !ok {
		t.Fatalf("program.Statements[0] is not ast.ExpressionStatement. got=%T",
			program.Statements[0])
	}

	ident, ok := stmt.Expression.(*ast.Identifier)
	if !ok {
		t.Fatalf("exp not *ast.Identifier. got=%T", stmt.Expression)
	}
	if ident.Value != "foobar" {
		t.Errorf("ident.Value not %s. got=%s", "foobar", ident.Value)
	}
	if ident.TokenLiteral() != "foobar" {
		t.Errorf("ident.TokenLiteral not %s. got=%s", "foobar",
			ident.TokenLiteral())
	}
}
```
有好多行啊，但主要是繁重的工作。我们解析我们的输入foobar；检查错误解析器，对*ast.Program节点中的语句数进行断言然后检查program.Statements中的语句是否是 *ast.ExpressionStatement。然后我们检查 *ast.ExpressionStatement.Expression是一个 *ast.Identifier。最后我们检查我们的标识符是否具有正确的“foobar”值。

当然，解析测试失败了：
```go
$ go test ./parser
--- FAIL: TestIdentifierExpression (0.00s)
parser_test.go:110: program has not enough statements. got=0
FAIL
FAIL monkey/parser 0.007s
```
解析不知道关于表达式中的任何东西。我们需要写一个parseExpression方法。

我们要做的第一件事是扩展解析器的parseStatement()方法，为了它解析表达式语句。由于 Monkey 中只有两种真正的语句类型是 let 和 return 语句，如果我们没有这其他两种语句之一，我们会尝试解析表达式语句：
```go
// parser/parser.go

func (p *Parser) parseStatement() ast.Statement {
    switch p.curToken.Type {
    case token.LET:
        return p.parseLetStatement()
    case token.RETURN:
        return p.parseReturnStatement()
    default:
        return p.parseExpressionStatement()
    }
}
```
parseExpressionStatement方法看起来像：
```go
// parser/parser.go

func (p *Parser) parseExpressionStatement() *ast.ExpressionStatement {
    stmt := &ast.ExpressionStatement{Token: p.curToken}

    stmt.Expression = p.parseExpression(LOWEST)
    if p.peekTokenIs(token.SEMICOLON) {
        p.nextToken()
    }

    return stmt
}
```

我们已经知道了联系：我们构建我们的AST节点并且然后尝试填充它的字段通过调用其他的解析函数。在这种情况下，虽然有一些区别：我们调用parseExpression()，它还不错你在，因为常量LOWEST，它还不存在，然后我们检查一个可选的分号。是的，这是可选的。如果peekToken是一个tokenSEMICOLON，我们前进所以它是curToken。如果它不存在，那也没关系，如果它不存在，我们不会向解析器添加错误。 那是因为我们希望表达式语句具有可选的分号（这使得稍后在 REPL 中键入诸如 5 + 5 之类的内容更容易）。

如果我们现在运行测试，我们可以看到编译失败了，因为LOWESST没有找到。那就对了，我们现在开始添加它，通过给Monkey编程语言定义优先级：
```go
// parser/parser.go

const (
    _ int = iota
    LOWEST
    EQUALS // ==
    LESSGREATER // > or <
    SUM // +
    PRODUCT // *
    PREFIX // -X or !X
    CALL // myFunction(X)
)
```
在这里我们使用iota来给出以下递增数字的常量作为值。空白标识符_取0值以下常量被赋值为1到7.其中我们使用的数字无关紧要，但顺序与彼此之间的关系很重要。我们希望从这些常量中得到的答案是：“*运算符是否比==运算符更高的优先级？前缀运算符是否比调用表达式具有更高的优先级？”

在parseExpressionStatement中，我们尽可能低的优先级传递给parseExpression,因为我们还没有解析任何东西，我们无法比较优先级。很快就会有更多意义，我保证。让我们编写parseExpression：
```go
// parser/parser.go

func (p *Parser) parseExpression(precedence int) ast.Expression {
    prefix := p.prefixParseFns[p.curToken.Type]
    if prefix == nil {
        return nil
    }
    leftExp := prefix()

    return leftExp
}
```
这是第一个版本。 它所做的只是检查我们是否在前缀位置有一个与 p.curToken.Type 相关联的解析函数。 如果我们这样做，它会调用这个解析函数，如果不是，它返回 nil。 目前它是这样做的，因为我们还没有将任何token与任何解析函数相关联。 这是我们的下一步：
```go
// parser/parser.go

func New(l *lexer.Lexer) *Parser {
// [...]
    p.prefixParseFns = make(map[token.TokenType]prefixParseFn)
    p.registerPrefix(token.IDENT, p.parseIdentifier)

// [...]
}
func (p *Parser) parseIdentifier() ast.Expression {
    return &ast.Identifier{Token: p.curToken, Value: p.curToken.Literal}
}
```
我们修改了New函数去初始化prefixParseFns map在Parser和注册一个解析函数：如果我们遇到了一个token类型未token.IDENT 解析函数就调用在*Parser中的parseIdentifier方法。

parseIdentifier方法没有做许多。它仅仅返回一个*ast.Identifier，在Token字段中包含当前token，在Value中返回token的字面值。它不推进token，也不调用nextToken。这很重要。我们所有的解析函数，prefixParseFn 或 infixParseFn，都将遵循这个协议：从 curToken 是你关联的 token 的类型开始，然后返回 curToken 作为你的表达式类型的最后一个标记。 永远不要将token推进得太远。

不管你信不信，我们的测试通过了：
```go
$ go test ./parser
ok monkey/parser 0.007s
```
我们成功解析了一个标识符表达式！ 好的！ 但是，在我们离开电脑之前，找个人，自豪地告诉他们，让我们屏住呼吸再写一些解析函数。

## 整数文字
与标识符几乎一样容易解析的是整数文字，如下所示：
```
5;
```
是的，这就是它。证书文字是表达式。它们产生的值是整数本身。再次，
想象在哪些地方可以出现整数文字来理解它们为什么是表达式：
```
let x = 5;
add(5, 10);
5 + 5 + 5;
```
我们能使用一些其他表达式代替整数文字在这里并且它将仍然有效：标识符、调用表达式、分组表达式、函数文字等。所有的表达类型可以互换，整数文字就是其中之一。整数文字的测试用例看卡里与标识符的测试用例非常相似：
```go
// parser/parser_test.go

func TestIntegerLiteralExpression(t *testing.T) {
	input := "5;"

	l := lexer.New(input)
	p := New(l)
	program := p.ParseProgram()
	checkParserErrors(t, p)

	if len(program.Statements) != 1 {
		t.Fatalf("program has not enough statements. got=%d",
			len(program.Statements))
	}
	stmt, ok := program.Statements[0].(*ast.ExpressionStatement)
	if !ok {
		t.Fatalf("program.Statements[0] is not ast.ExpressionStatement. got=%T",
			program.Statements[0])
	}

	literal, ok := stmt.Expression.(*ast.IntegerLiteral)
	if !ok {
		t.Fatalf("exp not *ast.IntegerLiteral. got=%T", stmt.Expression)
	}
	if literal.Value != 5 {
		t.Errorf("literal.Value not %d. got=%d", 5, literal.Value)
	}
	if literal.TokenLiteral() != "5" {
		t.Errorf("literal.TokenLiteral not %s. got=%s", "5",
			literal.TokenLiteral())
	}
}
```
就像在标识符的测试用例中一样，我们使用一个简单的输入，将它提供给解析器，然后检查解析器没有遇到任何错误并在*ast.Program.Statements中生成正确数量的语句。然后我们添加一个断言，即第一条语句是 *ast.ExpressionStatement。最后我们期待一个格式良好的 *ast.IntegerLiteral。测试不会编译，因为 *ast.IntergerLiteral还不存在。定义它很容易：
```go
// ast/ast.go

type IntegerLiteral struct {
    Token token.Token
    Value int64
}
func (il *IntegerLiteral) expressionNode() {}
func (il *IntegerLiteral) TokenLiteral() string { return il.Token.Literal }
func (il *IntegerLiteral) String() string { return il.Token.Literal }
```

*ast.IntegerLiteral 实现了 ast.Expression 接口，就像 *ast.Identifier 一样，但在结构本身上与 ast.Identifier 有显着区别：Value 是一个 int64 而不是字符串。 这是将包含整数文字在源代码中表示的实际值的字段。 当我们构建 *ast.IntegerLiteral 时，我们必须将 *ast.IntegerLiteral.Token.Literal 中的字符串（类似于“5”）转换为 int64。

最好的做的方式是在解析函数中和token.INT联系起来，叫做parseIntegerLiteral:
```go
// parser/parser.go

import (
// [...]
    "strconv"
)

func (p *Parser) parseIntegerLiteral() ast.Expression {
    lit := &ast.IntegerLiteral{Token: p.curToken}

    value, err := strconv.ParseInt(p.curToken.Literal, 0, 64)
    if err != nil {
        msg := fmt.Sprintf("could not parse %q as integer", p.curToken.Literal)
        p.errors = append(p.errors, msg)
        return nil
    }

    lit.Value = value

    return lit
}

```
像parseIdentifier方法简单。唯一不同的是调用strconv.Parselnt,它将p.curToken.Literal中的字符串转换为int64。然后int64被保存到Value字段，我们返回新构造的*ast.IntegerLiteral节点。如果这不起作用，我们会在解析器的错误字段中添加一个新错误。

但是测试还没有运行：
```go
$ go test ./parser
--- FAIL: TestIntegerLiteralExpression (0.00s)
parser_test.go:162: exp not *ast.IntegerLiteral. got=<nil>
FAIL
FAIL monkey/parser 0.008s
```
我们有nil代替一个*ast.IntegerLiteral在我们的AST。原因就是parseExpression无法为 token.INT 类型的标记找到 prefixParseFn。。为了让测试通过，我们所要做的就是注册我们的 parseIntegerLiteral 方法：
```go
// parser/parser.go

func New(l *lexer.Lexer) *Parser {
// [...]
    p.prefixParseFns = make(map[token.TokenType]prefixParseFn)
    p.registerPrefix(token.IDENT, p.parseIdentifier)
    p.registerPrefix(token.INT, p.parseIntegerLiteral)

// [...]
}
```
随着ParseIntegerLiteral注册了，parseExpression现在知道如何处理token.INT token，调用 parseIntegerLiteral 并返回它的返回值，一个 *ast.IntegerLiteral。 这次测试通过了：
```go
$ go test ./parser
ok monkey/parser 0.007s
```
我认为是时候说：我们顺利运行了！ 标识符和整数文字都在包里，让我们更进一步，解析前缀运算符。
## 前缀运算符
在Monkey语言中有两种前缀运算符:!和-。它们的用法与您对其他语言的期望非常相似：
```go
-5;
!foobar;
5 + -10;
```
它们遵循的使用结构：
```
<prefix operator><expression>;
```
是的，这是正确的
